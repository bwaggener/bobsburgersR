library(bobsburgersR)
source("C:/Users/poncest/OneDrive - Bristol Myers Squibb/RStudio/bobsburgersR/scrap.R", echo=TRUE)
devtools::install()
library(tidyverse)
library(bobsburgersR)
data(heatmap_data)
data("imdb_wikipedia_data")
glimpse(imdb_wikipedia_data)
data("imdb_wikipedia_data")
glimpse(imdb_wikipedia_data)
ggplot(imdb_wikipedia_data, aes(x = factor(season), y = rating)) +
geom_bar(stat = "summary", fun = "mean", fill = "#92C5DE") +
labs(x = "Season", y = "Average IMDb Rating", title = "Average IMDb Rating by Season")
ggplot(imdb_wikipedia_data, aes(x = imdb_aired_date, y = rating)) +
geom_line(color = "#0571B0") +
labs(x = "Aired Date", y = "IMDb Rating", title = "IMDb Ratings Over Time")
ggplot(imdb_wikipedia_data, aes(x = factor(season), y = rating)) +
geom_boxplot(fill = "#CA0020") +
labs(x = "Season", y = "IMDb Rating", title = "Distribution of IMDb Ratings by Season")
library(reshape2)
imdb_wikipedia_data$episode_combined <- paste(imdb_wikipedia_data$season, imdb_wikipedia_data$episode, sep = "-")
heatmap_data <- dcast(imdb_wikipedia_data, episode_combined ~ imdb_aired_date, value.var = "rating")
heatmap(as.matrix(heatmap_data[,-1]), Colv = NA, scale = "column", col = heat.colors(256))
ggplot(imdb_wikipedia_data, aes(x = wikipedia_directed_by, fill = wikipedia_written_by)) +
geom_bar() +
labs(x = "Director", fill = "Writer", title = "Episodes Directed and Written By")
data("transcript_data")
head(transcript_data)
## Heatmap: Lines Spoken by Season and Episode
# Summarize number of lines per episode per season
heatmap_data <- transcript_data |>
filter(!is.na(dialogue)) |>
group_by(season, episode) |>
summarize(total_lines = n()) |>
ungroup()
# Heatmap: Lines Spoken by Season and Episode
ggplot(heatmap_data, aes(x = as.factor(episode), y = as.factor(season), fill = total_lines)) +
geom_tile(color = "white") +
scale_fill_gradient(low = "lightyellow", high = "red") +
coord_equal() +
labs(
title = "Lines Spoken by Season and Episode",
x = "Episode",
y = "Season",
fill = "Total Lines"
) +
theme_minimal()
renv::status()
renv::snapshot()
devtools::document()
devtools::build()
devtools::document()
devtools::build()
devtools::document()
devtools::check()
list.files(recursive = TRUE)
fdd
devtools::check()
library(bobsburgersR)
data("imdb_wikipedia_data")
data("transcript_data")
str(imdb_wikipedia_data)
str(transcript_data)
devtools::build()
devtools::document()
devtools::check()
devtools::build()
devtools::document()
devtools::check()
?data
library(bobsburgersR)
data("imdb_wikipedia_data")
data("transcript_data")
str(imdb_wikipedia_data)
str(transcript_data)
devtools::build()
devtools::document()
devtools::check()
devtools::build()
devtools::document()
devtools::check()
names(imdb_wikipedia_data)
names(transcript_data)
devtools::build()
devtools::document()
sapply(imdb_wikipedia_data, class)
sapply(transcript_data, class)
devtools::check(args = "--as-cran", quiet = FALSE)
imdb_wikipedia_data <- read.csv("data_raw/IMDb_Bobs_Burgers_Data.csv")
imdb_wikipedia_data <- read_csv("data_raw/IMDb_Bobs_Burgers_Data.csv")
library(bobsburgersR)
library(tidyverse)
imdb_wikipedia_data <- read_csv("data_raw/IMDb_Bobs_Burgers_Data.csv")
imdb_wikipedia_data <- read_csv("data-raw/IMDb_Wikipedia_Bobs_Burgers_Data_Clean.csv")
View(imdb_wikipedia_data)
## 1. LOAD PACKAGES & SETUP ----
pacman::p_load(
tidyverse,   # Easily Install and Load the 'Tidyverse'
ggtext,      # Improved Text Rendering Support for 'ggplot2'
showtext,    # Using Fonts More Easily in R Graphs
janitor,     # Simple Tools for Examining and Cleaning Dirty Data
skimr,       # Compact and Flexible Summaries of Data
scales,      # Scale Functions for Visualization
lubridate,   # Make Dealing with Dates a Little Easier
glue,        # Interpreted String Literals
fuzzyjoin    # Join Tables Together on Inexact Matching
)
imdb_data <- read_csv('00_data/01_raw_data/IMDb_Bobs_Burgers_Data.csv') |>
clean_names() |>
glimpse()
read_csv('data-raw/IMDb_Bobs_Burgers_Data.csv') |>
clean_names() |>
glimpse()
imdb_data <- read_csv('data-raw/IMDb_Bobs_Burgers_Data.csv') |>
clean_names() |>
glimpse()
wikipedia_data <- read_csv('data-raw/Wikipedia_Bobs_Burgers_Data.csv') |>
clean_names() |>
glimpse()
View(wikipedia_data)
imdb_data <- read_csv('data-raw/IMDb_Bobs_Burgers_Data.csv') |>
clean_names() |>
glimpse() |>
select(-x1)
imbd_data |> select(x1)
imdb_data |> select(x1)
colnames(imdb_data)
View(imdb_data)
imdb_data <- read_csv('data-raw/IMDb_Bobs_Burgers_Data.csv') |>
clean_names() |>
glimpse()
imdb_data <- read_csv('data-raw/IMDb_Bobs_Burgers_Data.csv') |>
clean_names() |>
select(x1 |> )
imdb_data <- read_csv('data-raw/IMDb_Bobs_Burgers_Data.csv') |>
clean_names() |>
select(x1) |>
glimpse()
imdb_data <- read_csv('data-raw/IMDb_Bobs_Burgers_Data.csv') |>
clean_names() |>
select(-x1) |>
glimpse()
wikipedia_data <- read_csv('data-raw/Wikipedia_Bobs_Burgers_Data.csv') |>
clean_names() |>
select(-x1) |>
glimpse()
# Step 1: Clean the title Column in Wikipedia Data
# Clean the 'title' column in wikipedia_data
wikipedia_data <- wikipedia_data |>
mutate(title = str_replace_all(title, "\"", ""))
# Step 2: Perform an Exact Join
# Perform an exact join using episode_overall, season, and episode
combined_data_exact <- imdb_data |>
left_join(wikipedia_data, by = c("episode_overall", "season", "episode"))
# Check the result
glimpse(combined_data_exact)
# Step 3: Check for Missing Data After the Exact Join
# Check for rows in IMDb data that didn't match Wikipedia data (missing Wikipedia info)
missing_in_wikipedia <- imdb_data |>
anti_join(wikipedia_data, by = c("episode_overall", "season", "episode"))
# View the unmatched IMDb episodes
print(missing_in_wikipedia)
# Step 4: Perform a Fuzzy Join on Titles
# Perform a fuzzy join on the 'title' column
combined_data_fuzzy <- imdb_data |>
stringdist_left_join(wikipedia_data, by = "title", max_dist = 1) # Adjust max_dist as needed
# Glimpse the fuzzy joined data
glimpse(combined_data_fuzzy)
# Step 5: Check for Duplicates in the Fuzzy Join
# Check for duplicate matches after the fuzzy join
duplicate_matches <- combined_data_fuzzy |>
group_by(episode_overall.x, season.x, episode.x) |>
filter(n() > 1)
# View the duplicate matches
print(duplicate_matches)
# Step 6: Identify Mismatched Titles in the Fuzzy Join
# Find rows where IMDb and Wikipedia titles do not exactly match
mismatch_titles <- combined_data_fuzzy |>
filter(title.x != title.y)
# View the mismatched titles
print(mismatch_titles)
# Step 7: Handle Duplicates and Incorrect Matches
# Keep only the first match for each episode
combined_data_clean <- combined_data_fuzzy |>
distinct(episode_overall.x, season.x, episode.x, .keep_all = TRUE)
# Glimpse the cleaned data
glimpse(combined_data_clean)
# Step 8: Final Clean-Up and Renaming Columns
# Remove unnecessary duplicate columns and rename columns
combined_data_clean <- combined_data_clean |>
select(-x1.y, -aired_date.y, -year.y, -season.y, -episode.y, -title.y) |>
rename(
imdb_aired_date = aired_date.x,
imdb_title = title.x,
wikipedia_viewers = us_viewers_millions,
wikipedia_directed_by = directed_by,
wikipedia_written_by = written_by,
episode_overall = episode_overall.x,
year = year.x,
season = season.x,
episode = episode.x
) |>
# Drop unnecessary or duplicate columns
select(-x1.x, -episode_overall.y)
# Glimpse the final cleaned data
glimpse(combined_data_clean)
# Step 9: Remove Temporary Datasets
# Remove temporary or intermediate datasets
rm(combined_data_fuzzy, combined_data_exact, mismatch_titles, duplicate_matches,
missing_in_wikipedia, imdb_data, wikipedia_data)
## 6. SAVE ----
write.csv(
combined_data_clean,
"00_data/02_clean_data/IMDb_Wikipedia_Bobs_Burgers_Data_Clean.csv"
)
## 6. SAVE ----
write.csv(
combined_data_clean,
"data-raw/IMDb_Wikipedia_Bobs_Burgers_Data_Clean.csv"
)
View(imdb_wikipedia_data)
View(combined_data_clean)
imdb_data <- read_csv('data-raw/IMDb_Bobs_Burgers_Data.csv') |>
clean_names() |>
glimpse()
wikipedia_data <- read_csv('data-raw/Wikipedia_Bobs_Burgers_Data.csv') |>
clean_names() |>
glimpse()
# Step 1: Clean the title Column in Wikipedia Data
# Clean the 'title' column in wikipedia_data
wikipedia_data <- wikipedia_data |>
mutate(title = str_replace_all(title, "\"", ""))
# Step 2: Perform an Exact Join
# Perform an exact join using episode_overall, season, and episode
combined_data_exact <- imdb_data |>
left_join(wikipedia_data, by = c("episode_overall", "season", "episode"))
# Check the result
glimpse(combined_data_exact)
# Step 3: Check for Missing Data After the Exact Join
# Check for rows in IMDb data that didn't match Wikipedia data (missing Wikipedia info)
missing_in_wikipedia <- imdb_data |>
anti_join(wikipedia_data, by = c("episode_overall", "season", "episode"))
# View the unmatched IMDb episodes
print(missing_in_wikipedia)
# Step 4: Perform a Fuzzy Join on Titles
# Perform a fuzzy join on the 'title' column
combined_data_fuzzy <- imdb_data |>
stringdist_left_join(wikipedia_data, by = "title", max_dist = 1) # Adjust max_dist as needed
# Glimpse the fuzzy joined data
glimpse(combined_data_fuzzy)
# Step 5: Check for Duplicates in the Fuzzy Join
# Check for duplicate matches after the fuzzy join
duplicate_matches <- combined_data_fuzzy |>
group_by(episode_overall.x, season.x, episode.x) |>
filter(n() > 1)
# View the duplicate matches
print(duplicate_matches)
# Step 6: Identify Mismatched Titles in the Fuzzy Join
# Find rows where IMDb and Wikipedia titles do not exactly match
mismatch_titles <- combined_data_fuzzy |>
filter(title.x != title.y)
# View the mismatched titles
print(mismatch_titles)
# Step 7: Handle Duplicates and Incorrect Matches
# Keep only the first match for each episode
combined_data_clean <- combined_data_fuzzy |>
distinct(episode_overall.x, season.x, episode.x, .keep_all = TRUE)
# Glimpse the cleaned data
glimpse(combined_data_clean)
# Step 8: Final Clean-Up and Renaming Columns
# Remove unnecessary duplicate columns and rename columns
combined_data_clean <- combined_data_clean |>
select(-x1.y, -aired_date.y, -year.y, -season.y, -episode.y, -title.y) |>
rename(
imdb_aired_date = aired_date.x,
imdb_title = title.x,
wikipedia_viewers = us_viewers_millions,
wikipedia_directed_by = directed_by,
wikipedia_written_by = written_by,
episode_overall = episode_overall.x,
year = year.x,
season = season.x,
episode = episode.x
) |>
# Drop unnecessary or duplicate columns
select(-x1.x, -episode_overall.y)
# Glimpse the final cleaned data
glimpse(combined_data_clean)
# Step 9: Remove Temporary Datasets
# Remove temporary or intermediate datasets
rm(combined_data_fuzzy, combined_data_exact, mismatch_titles, duplicate_matches,
missing_in_wikipedia, imdb_data, wikipedia_data)
## 6. SAVE ----
write.csv(
combined_data_clean,
"data-raw/IMDb_Wikipedia_Bobs_Burgers_Data_Clean.csv"
)
imdb_data <- read_csv('data-raw/IMDb_Bobs_Burgers_Data.csv') |>
clean_names() |>
glimpse()
wikipedia_data <- read_csv('data-raw/Wikipedia_Bobs_Burgers_Data.csv') |>
clean_names() |>
glimpse()
# Step 1: Clean the title Column in Wikipedia Data
# Clean the 'title' column in wikipedia_data
wikipedia_data <- wikipedia_data |>
mutate(title = str_replace_all(title, "\"", ""))
# Step 2: Perform an Exact Join
# Perform an exact join using episode_overall, season, and episode
combined_data_exact <- imdb_data |>
left_join(wikipedia_data, by = c("episode_overall", "season", "episode"))
# Check the result
glimpse(combined_data_exact)
# Step 3: Check for Missing Data After the Exact Join
# Check for rows in IMDb data that didn't match Wikipedia data (missing Wikipedia info)
missing_in_wikipedia <- imdb_data |>
anti_join(wikipedia_data, by = c("episode_overall", "season", "episode"))
# View the unmatched IMDb episodes
print(missing_in_wikipedia)
# Step 4: Perform a Fuzzy Join on Titles
# Perform a fuzzy join on the 'title' column
combined_data_fuzzy <- imdb_data |>
stringdist_left_join(wikipedia_data, by = "title", max_dist = 1) # Adjust max_dist as needed
# Glimpse the fuzzy joined data
glimpse(combined_data_fuzzy)
# Step 5: Check for Duplicates in the Fuzzy Join
# Check for duplicate matches after the fuzzy join
duplicate_matches <- combined_data_fuzzy |>
group_by(episode_overall.x, season.x, episode.x) |>
filter(n() > 1)
# View the duplicate matches
print(duplicate_matches)
# Step 6: Identify Mismatched Titles in the Fuzzy Join
# Find rows where IMDb and Wikipedia titles do not exactly match
mismatch_titles <- combined_data_fuzzy |>
filter(title.x != title.y)
# View the mismatched titles
print(mismatch_titles)
# Step 7: Handle Duplicates and Incorrect Matches
# Keep only the first match for each episode
combined_data_clean <- combined_data_fuzzy |>
distinct(episode_overall.x, season.x, episode.x, .keep_all = TRUE)
# Glimpse the cleaned data
glimpse(combined_data_clean)
# Step 8: Final Clean-Up and Renaming Columns
# Remove unnecessary duplicate columns and rename columns
combined_data_clean <- combined_data_clean |>
select(-x1.y, -aired_date.y, -year.y, -season.y, -episode.y, -title.y) |>
rename(
imdb_aired_date = aired_date.x,
imdb_title = title.x,
wikipedia_viewers = us_viewers_millions,
wikipedia_directed_by = directed_by,
wikipedia_written_by = written_by,
episode_overall = episode_overall.x,
year = year.x,
season = season.x,
episode = episode.x
) |>
# Drop unnecessary or duplicate columns
select(-x1.x, -episode_overall.y)
# Glimpse the final cleaned data
glimpse(combined_data_clean)
View(combined_data_clean)
## 6. SAVE ----
write_csv(
combined_data_clean,
"data-raw/IMDb_Wikipedia_Bobs_Burgers_Data_Clean.csv"
)
## 1. LOAD PACKAGES & SETUP ----
pacman::p_load(
tidyverse,   # Easily Install and Load the 'Tidyverse'
ggtext,      # Improved Text Rendering Support for 'ggplot2'
showtext,    # Using Fonts More Easily in R Graphs
janitor,     # Simple Tools for Examining and Cleaning Dirty Data
skimr,       # Compact and Flexible Summaries of Data
scales,      # Scale Functions for Visualization
lubridate,   # Make Dealing with Dates a Little Easier
glue         # Interpreted String Literals
)
## 2. READ IN THE DATA ----
transcript <- read_csv("data-raw/Transcript_Bobs_Burgers_Data.csv") |>
clean_names() |>
glimpse()
# Remove '=' from the dialogue column
transcript_clean <- transcript  |>
mutate(dialogue = str_replace_all(dialogue, "=", ""))
## 4. SAVE ----
write_csv(
transcript_clean,
"data-raw/Transcript_Bobs_Burgers_Data_Clean.csv"
)
imdb_wikipedia_data <- read_csv("data/IMDb_Wikipedia_Bobs_Burgers_Data_Clean.csv")
imdb_wikipedia_data <- read_csv("data-raw/IMDb_Wikipedia_Bobs_Burgers_Data_Clean.csv")
transcript_data <- read_csv("data-raw/Transcript_Bobs_Burgers_Data_Clean.csv")
View(imdb_wikipedia_data)
usethis::use_data(imdb_wikipedia_data, overwrite = TRUE)
usethis::use_data(transcript_data, overwrite = TRUE)
data("imdb_wikipedia_data")
devtools::document()
devtools::build()
devtools::load_all()
force(imdb_wikipedia_data)
devtools::load_all()
data("imdb_wikipedia_data")
data("transcript_data")
devtools::document()
str(imdb_wikipedia_data)
str(transcript_data)
names(imdb_wikipedia_data)
names(transcript_data)
devtools::document()
devtools::check()
devtools::install()
rmarkdown::render("README.Rmd")
install.packages("knitr")
install.packages("rmarkdown")
rmarkdown::render("README.Rmd")
.libPaths()
